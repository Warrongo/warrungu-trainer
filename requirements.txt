# ===================================================================================
# Minimal requirements.txt for running Axolotl 0.9.0 + Mistral-7B-Instruct in a Space
# ===================================================================================

# 1) Core Axolotl (locks several transitive deps):
axolotl==0.9.0
packaging==23.2

# 2) BitsAndBytes, PEFT, and related low-level libs:
bitsandbytes==0.45.4
peft==0.15.2
triton>=3.0.0
xformers>=0.0.23.post1
autoawq==0.2.7.post3
liger-kernel==0.5.8

# 3) HF + Transformers + Accelerate + Datasets:
huggingface_hub==0.30.1
transformers==4.51.3
tokenizers>=0.21.1
accelerate==1.6.0
datasets==3.5.0
deepspeed>=0.15.4
trl==0.17.0
hf_xet==1.0.0
hqq==0.2.5
optimum==1.16.2

# 4) Basic model/tokenizer support:
sentencepiece
torch>=2.0.0

# 5) Utilities needed by run.sh / data prep / logging:
wget
PyYAML>=6.0
requests
colorama
einops
numpy>=1.24.4,<=2.0.1

# 6) (Optional) LoRA-specific & eval harness – remove if you don’t need them:
evaluate==0.4.1
torchao==0.9.0
tensorboard
